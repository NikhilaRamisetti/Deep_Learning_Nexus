{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Neural Network Implementation\n",
        "\n",
        "\n",
        "**Objective: Building a Basic Neural Network Implementation**\n",
        "\n",
        "The primary objective of this implementation is to create a basic neural network from scratch, emphasizing key neural network concepts and processes. The focus is on understanding and implementing fundamental components, including input, output, and hidden layers, activation functions, weights and biases, feedforward and backpropagation, loss function, and optimization.\n",
        "\n",
        "Further, The code implementation includes an example usage with the specified dataset, and the neural network is trained to predict product purchases based on age and income features."
      ],
      "metadata": {
        "id": "05P4NNtYXkQN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GfSEHVc2FFuC"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from random import seed, random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A neural network lacks meaningful functionality without trained and defined parameters; without proper training, it remains a structure devoid of value in terms of fulfilling its intended functions.\n",
        "\n",
        "So lets start my initializing these parameters.\n",
        "\n",
        "**Key Components of the Neural Network:**\n",
        "\n",
        "1. **Neural Network Architecture:**\n",
        "   - The neural network architecture is designed with\n",
        "    - an input layer - To recieve features.\n",
        "    - a hidden layer - To process information.\n",
        "    - an output layer - To produce predictions.\n",
        "\n",
        "2. **Activation Functions:**\n",
        "   - Sigmoid activation functions are employed in the hidden and output layers to introduce non-linearity.\n",
        "\n",
        "3. **Weights and Biases:**\n",
        "   - Weights - To represent the strength of connections between neurons.\n",
        "   - Biases - To provide flexibility in modeling.\n",
        "\n",
        "4. **Feedforward Process:**\n",
        "   - The feedforward process involves passing inputs through the network to generate predictions.\n",
        "   - The hidden layer receives weighted inputs, applies activation functions, and produces outputs fed to the output layer.\n",
        "\n",
        "5. **Backpropagation:**\n",
        "   - Backpropagation is utilized for training the neural network.\n",
        "   - During backpropagation, errors are calculated, and gradients are used to update weights and biases, minimizing the difference between predicted and actual outputs.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7LAuNb5_Drw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the NeuralNetwork class\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        # Initializing neural network parameters\n",
        "        self.weights_input_hidden = np.random.randn(input_size, hidden_size)\n",
        "        self.bias_hidden = np.zeros((1, hidden_size))\n",
        "        self.weights_hidden_output = np.random.randn(hidden_size, output_size)\n",
        "        self.bias_output = np.zeros((1, output_size))\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def forward_propagation(self, inputs):\n",
        "        # Calculating hidden layer output\n",
        "        self.hidden_layer_input = np.dot(inputs, self.weights_input_hidden) + self.bias_hidden\n",
        "        self.hidden_layer_output = self.sigmoid(self.hidden_layer_input)\n",
        "\n",
        "        # Calculating output layer output\n",
        "        self.output_layer_input = np.dot(self.hidden_layer_output, self.weights_hidden_output) + self.bias_output\n",
        "        self.predicted_output = self.sigmoid(self.output_layer_input)\n",
        "\n",
        "    def backward_propagation(self, inputs, targets):\n",
        "        # Calculating output layer error and delta\n",
        "        output_error = targets - self.predicted_output\n",
        "        output_delta = output_error * self.sigmoid_derivative(self.predicted_output)\n",
        "\n",
        "        # Calculating hidden layer error and delta\n",
        "        hidden_error = output_delta.dot(self.weights_hidden_output.T)\n",
        "        hidden_delta = hidden_error * self.sigmoid_derivative(self.hidden_layer_output)\n",
        "\n",
        "        # Updating weights and biases\n",
        "        self.weights_hidden_output += self.hidden_layer_output.T.dot(output_delta) * learning_rate\n",
        "        self.bias_output += np.sum(output_delta, axis=0, keepdims=True) * learning_rate\n",
        "        self.weights_input_hidden += inputs.T.dot(hidden_delta) * learning_rate\n",
        "        self.bias_hidden += np.sum(hidden_delta, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    def train(self, inputs, targets, epochs, learning_rate=0.01):\n",
        "      for epoch in range(epochs):\n",
        "        # Forward propagation\n",
        "        self.forward_propagation(inputs)\n",
        "\n",
        "        # Backward propagation\n",
        "        self.backward_propagation(inputs, targets)"
      ],
      "metadata": {
        "id": "_fbPrCbPreKa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example usage for product purchase prediction based on age and income dataset\n",
        "\n",
        "After initializing a neural network class and demonstrates its usage usage on a dataset representing people's age, income, and whether they bought a product or not.\n",
        "\n",
        "The dataset is small and used for binary classification (0: Not buy, 1: Buy).\n",
        "\n"
      ],
      "metadata": {
        "id": "VDo2_yN2kD-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 2\n",
        "hidden_size = 3\n",
        "output_size = 1"
      ],
      "metadata": {
        "id": "cnJfF1QGQLsR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neural_network = NeuralNetwork(input_size, hidden_size, output_size)"
      ],
      "metadata": {
        "id": "HxjQMVDbmXa6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Features (age, income)\n",
        "inputs = np.array([\n",
        "    [25, 50000],\n",
        "    [35, 75000],\n",
        "    [45, 100000],\n",
        "    [20, 30000],\n",
        "    [50, 120000],\n",
        "    [30, 80000]\n",
        "])\n",
        "\n",
        "# Targets (0: Not buy, 1: Buy)\n",
        "targets = np.array([[0], [1], [1], [0], [1], [1]])\n"
      ],
      "metadata": {
        "id": "g1iGpCTAmgKj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training the neural network on the above data\n",
        "epochs = 1000000\n",
        "learning_rate =0.05\n",
        "neural_network.train(inputs, targets, epochs, learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltuos4nmm6Gg",
        "outputId": "8e56b579-ad26-4e0d-c4dd-85c4fe6b87b2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-6790fc04914c>:11: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-x))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the trained network for predictions\n",
        "for data_point in inputs:\n",
        "    neural_network.forward_propagation(data_point)\n",
        "    prediction = 1 if neural_network.predicted_output >= 0.5 else 0\n",
        "    print(f\"Prediction for {data_point}: {prediction}\")"
      ],
      "metadata": {
        "id": "ziu86A3wnEO7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}